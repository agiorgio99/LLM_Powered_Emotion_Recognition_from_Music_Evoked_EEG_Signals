{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilNCK1uq1F6h"
      },
      "source": [
        "# Drive mount & Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH5yMaFqiD7M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trRWWIyk1K_m"
      },
      "outputs": [],
      "source": [
        "!pip install -q hf_xet hdf5storage pyyaml transformers accelerate scikit-learn wandb peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1C92y7qxf1e"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade \"transformers>=4.41\" accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XMFcwd-0XPu"
      },
      "source": [
        "# Dataset preprocessing & LLMs download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4erPXdNnj_N"
      },
      "outputs": [],
      "source": [
        "# import glob, os, scipy.io, numpy as np\n",
        "\n",
        "# SRC_DIR   = '/content/drive/MyDrive/THESIS/DEAP_Dataset/data_preprocessed_matlab'\n",
        "# DST_FILE  = '/content/drive/MyDrive/THESIS/deap_preprocess_eeg+peripheral_32_40_40_60_128.mat'\n",
        "\n",
        "# files = sorted(glob.glob(os.path.join(SRC_DIR, 's*.mat')))\n",
        "# assert len(files) == 32, 'Need 32 subject files'\n",
        "\n",
        "# X_all, Y_all = [], []\n",
        "# for f in files:\n",
        "#     m      = scipy.io.loadmat(f)\n",
        "#     data   = m['data']          # (40, 40, 8064)\n",
        "#     labels = m['labels']        # (40, 4)\n",
        "\n",
        "#     # remove 3-second baseline â†’ keep final 60 s\n",
        "#     data = data[:, :, 384:]                     # (40, 40, 7680)\n",
        "#     data = data.reshape(40, 40, 60, 128)        # (trials, ch, 60, 128)\n",
        "\n",
        "#     X_all.append(data)\n",
        "#     Y_all.append(labels)\n",
        "#     print('loaded', os.path.basename(f), data.shape)\n",
        "\n",
        "# X = np.stack(X_all, axis=0)   # (32, 40, 40, 60, 128)\n",
        "# Y = np.stack(Y_all, axis=0)   # (32, 40, 4)\n",
        "# print('final shapes', X.shape, Y.shape)\n",
        "\n",
        "# scipy.io.savemat(DST_FILE, {'X': X, 'Y': Y})\n",
        "# print('saved to', DST_FILE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv0B3d9G2hau"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p \"/content/drive/MyDrive/THESIS/GPT-2\"\n",
        "\n",
        "# from transformers import GPT2Model\n",
        "\n",
        "# LOCAL_DIR = \"/content/drive/MyDrive/THESIS/GPT-2\"\n",
        "# model = GPT2Model.from_pretrained(\"gpt2\")\n",
        "# model.save_pretrained(LOCAL_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVp1_M3XMi40"
      },
      "outputs": [],
      "source": [
        "# !pip install -q huggingface_hub\n",
        "# from huggingface_hub import login\n",
        "\n",
        "# # Inserisci il token come stringa\n",
        "# login(token=\"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\")  # <-- incolla qui il tuo token\n",
        "\n",
        "# from huggingface_hub import snapshot_download\n",
        "\n",
        "# snapshot_download(\n",
        "#     repo_id=\"meta-llama/Llama-3.2-1B\",\n",
        "#     local_dir=\"/content/Llama-3.2-1B\",           # << salviamo su Colab, non Drive\n",
        "#     local_dir_use_symlinks=False,\n",
        "#     resume_download=True                         # << forza il completamento\n",
        "# )\n",
        "\n",
        "# !cp -r /content/Llama-3.2-1B /content/drive/MyDrive/THESIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGVahiEBY3xH"
      },
      "outputs": [],
      "source": [
        "# !pip install -q huggingface_hub\n",
        "# from huggingface_hub import login, snapshot_download # Import snapshot_download\n",
        "\n",
        "# # Inserisci il token come stringa\n",
        "# login(token=\"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\")  # <-- incolla qui il tuo token\n",
        "\n",
        "# REPO_ID   = \"hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\"\n",
        "# TARGET    = Path(\"/content/drive/MyDrive/THESIS/Llama-3.1-8B-INT4\")\n",
        "\n",
        "# snapshot_download(\n",
        "#     repo_id           = REPO_ID,\n",
        "#     local_dir         = TARGET,\n",
        "#     local_dir_use_symlinks=False,   # Drive dislikes symlinks\n",
        "#     resume_download   = True,\n",
        "# )\n",
        "# print(\"âœ“ Model files are now in\", TARGET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWG4rmE5CxJ9"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForCausalLM, GPT2Config, AutoTokenizer\n",
        "# import torch\n",
        "# import os\n",
        "\n",
        "# # Function to cache model weights\n",
        "# def cache_model_weights(model_type, model_path, cache_dir=\"/content/llm_cached\"):\n",
        "#     \"\"\"\n",
        "#     Caches the model weights and configuration for faster future loads.\n",
        "#     \"\"\"\n",
        "#     os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "#     if model_type == \"gpt2\":\n",
        "#         # Load GPT-2 model with modified config\n",
        "#         config = GPT2Config.from_pretrained(\n",
        "#             model_path,\n",
        "#             n_embd=768,  # Adjust as needed\n",
        "#             n_layer=12,\n",
        "#             n_head=12,\n",
        "#             resid_pdrop=0.1,\n",
        "#             attn_pdrop=0.1,\n",
        "#             embd_pdrop=0.1,\n",
        "#             activation_function=\"gelu\"\n",
        "#         )\n",
        "#         model = AutoModelForCausalLM.from_pretrained(model_path, config=config, local_files_only=True)\n",
        "#     elif model_type == \"llama\":\n",
        "#         # Load Llama model (replace with actual logic for 4-bit + LoRA, etc.)\n",
        "#         model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
        "#     else:\n",
        "#         raise ValueError(\"Unknown model type!\")\n",
        "\n",
        "#     # Save the model to cache directory\n",
        "#     model.save_pretrained(cache_dir)\n",
        "#     print(f\"Model weights cached at {cache_dir}\")\n",
        "\n",
        "# # Cache GPT-2\n",
        "# cache_model_weights(\"gpt2\", \"/content/drive/MyDrive/THESIS/GPT-2\", \"/content/gpt2\")\n",
        "\n",
        "# # Cache Llama\n",
        "# cache_model_weights(\"llama\", \"/content/drive/MyDrive/THESIS/Llama-3.1-8B-Instruct\", \"/content/llama\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbDPFdl-0nLU"
      },
      "source": [
        "# IMPORT & WANDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJYA5AJX05y5"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import scipy.io, hdf5storage\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random, os, yaml, argparse\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import json, tempfile, shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import (\n",
        "    GPT2Model, GPT2Config,\n",
        "    AutoModel, AutoConfig,\n",
        "    AutoModelForCausalLM, BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import time, pytz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from torch.amp import autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9P1PmynQRc_"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"4f1fd29237ed9d0652777c7ebb441a170b7c8c6d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GXhqd_b7rcu"
      },
      "source": [
        "# MODEL COMPONENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ownmpTbu76DR"
      },
      "outputs": [],
      "source": [
        "class EEGTransformer(nn.Module):\n",
        "    \"\"\"Temporal Transformer encoder operating on EEG sequences.\"\"\"\n",
        "    def __init__(self, d_eeg: int, seq_length: int, feature_dim: int, output_dim: int):\n",
        "        super().__init__()\n",
        "        self.fc_map      = nn.Linear(d_eeg, feature_dim)\n",
        "        self.layer_norm  = nn.LayerNorm([seq_length, d_eeg])\n",
        "        self.dropout     = nn.Dropout(0.1)\n",
        "        self.pos_encoder = nn.Embedding(seq_length, feature_dim)\n",
        "        self.self_attn   = nn.TransformerEncoderLayer(\n",
        "                              d_model=feature_dim, nhead=8, batch_first=False)\n",
        "        self.fusion_linear = nn.Linear(feature_dim, output_dim)\n",
        "\n",
        "    def forward(self, eeg_seq: torch.Tensor) -> torch.Tensor:\n",
        "        B, T, D = eeg_seq.shape\n",
        "        assert D == self.fc_map.in_features, \"EEG channel dimension mismatch\"\n",
        "        eeg_seq = self.layer_norm(eeg_seq)\n",
        "        eeg_seq = self.dropout(F.relu(self.fc_map(eeg_seq)))\n",
        "        pos     = torch.arange(T, device=eeg_seq.device)\\\n",
        "                        .unsqueeze(0).repeat(B, 1)\n",
        "        eeg_seq = eeg_seq + self.pos_encoder(pos)\n",
        "        eeg_seq = eeg_seq.permute(1, 0, 2)  # (T, B, C)\n",
        "        eeg_seq = self.self_attn(eeg_seq)\n",
        "        eeg_seq = eeg_seq.permute(1, 0, 2)\n",
        "        eeg_seq = torch.mean(eeg_seq, dim=1)\n",
        "        return self.fusion_linear(eeg_seq)\n",
        "\n",
        "class FinalClassifier(nn.Module):\n",
        "    \"\"\"Classifier that flattens the chunk dimension and predicts labels.\"\"\"\n",
        "    def __init__(self, n_embd: int, num_chunks: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.num_chunks = num_chunks\n",
        "        input_dim  = n_embd * num_chunks\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim // 2), nn.ReLU(),\n",
        "            nn.Linear(input_dim // 2, input_dim // 4), nn.ReLU(),\n",
        "            nn.Linear(input_dim // 4, n_embd),    nn.ReLU(),\n",
        "        )\n",
        "        self.head = nn.Linear(n_embd, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        B, C, D = x.shape\n",
        "        assert C == self.num_chunks, \"num_chunks mismatch in FinalClassifier\"\n",
        "        x = x.contiguous().view(B, -1)\n",
        "        mid = self.backbone(x)\n",
        "        logits = self.head(mid)\n",
        "        return mid, logits\n",
        "\n",
        "def laplacian(w: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Compute normalized Laplacian from adjacency matrix.\"\"\"\n",
        "    d    = torch.sum(w, dim=1)\n",
        "    d_re = 1 / torch.sqrt(d + 1e-5)\n",
        "    Dm   = torch.diag_embed(d_re)\n",
        "    return torch.eye(Dm.shape[0], device=w.device) - Dm @ w @ Dm\n",
        "\n",
        "class GraphConv(nn.Module):\n",
        "    \"\"\"Chebyshev graph convolution.\"\"\"\n",
        "    def __init__(self, k: int, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "        self.k           = k\n",
        "        self.in_channels = in_channels\n",
        "        self.weight      = nn.Parameter(torch.empty(k * in_channels, out_channels))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def chebyshev(self, x, lap):\n",
        "        t0 = torch.ones_like(x)\n",
        "        if self.k == 1:\n",
        "            return t0.unsqueeze(1)\n",
        "        t1 = lap @ x\n",
        "        if self.k == 2:\n",
        "            return torch.stack([t0, t1], dim=1)\n",
        "        cheb = [t0, t1]\n",
        "        for _ in range(2, self.k):\n",
        "            t2 = 2 * (lap @ cheb[-1]) - cheb[-2]\n",
        "            cheb.append(t2)\n",
        "        return torch.stack(cheb, dim=1)\n",
        "\n",
        "    def forward(self, x, lap):\n",
        "        cp = self.chebyshev(x, lap)               # (B, K, ele, in)\n",
        "        cp = cp.permute(0, 2, 3, 1).flatten(start_dim=2)  # (B, ele, in*K)\n",
        "        return cp @ self.weight                   # (B, ele, out)\n",
        "\n",
        "class B1ReLU(nn.Module):\n",
        "    def __init__(self, bias_shape):\n",
        "        super().__init__()\n",
        "        self.bias = nn.Parameter(torch.zeros(1, 1, bias_shape))\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bias + x)\n",
        "\n",
        "class DGCNN(nn.Module):\n",
        "    \"\"\"Dynamic graph CNN acting as spatial encoder.\"\"\"\n",
        "    def __init__(self, num_electrodes=32, in_channels=512,\n",
        "                 num_embed=128, k=2, layers=None, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        layers = layers or [128]\n",
        "        self.graphConvs = nn.ModuleList([\n",
        "            GraphConv(k, in_channels if i == 0 else layers[i-1], layers[i])\n",
        "            for i in range(len(layers))\n",
        "        ])\n",
        "        self.b_relus = nn.ModuleList([B1ReLU(layers[i]) for i in range(len(layers))])\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc      = nn.Linear(num_electrodes * layers[-1], num_embed)\n",
        "        self.adj     = nn.Parameter(torch.empty(num_electrodes, num_electrodes))\n",
        "        self.adj_bias= nn.Parameter(torch.zeros(1))\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        nn.init.xavier_uniform_(self.adj)\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        adj = self.relu(self.adj + self.adj_bias)\n",
        "        lap = laplacian(adj)\n",
        "        for conv, brelu in zip(self.graphConvs, self.b_relus):\n",
        "            x = conv(x, lap)\n",
        "            x = self.dropout(x)\n",
        "            x = brelu(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2):\n",
        "        super().__init__(); self.gamma = gamma\n",
        "    def forward(self, logits, targets):\n",
        "        ce = F.cross_entropy(logits, targets, reduction=\"none\")\n",
        "        p  = torch.exp(-ce)\n",
        "        return ((1 - p) ** self.gamma * ce).mean()\n",
        "\n",
        "\n",
        "\n",
        "# helper to mark peak\n",
        "def annotate_peak(ax, xs, ys):\n",
        "    idx = int(np.argmax(ys))\n",
        "    ax.plot(xs[idx], ys[idx], 'o')\n",
        "    ax.annotate(f\"{ys[idx]:.3f}\", (xs[idx], ys[idx]),\n",
        "                textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# LLM factory\n",
        "# -----------------------------------------------------------------------\n",
        "def instantiate_llm(args):\n",
        "    \"\"\"\n",
        "    Return (llm, n_embd) according to args.llm_model.\n",
        "    Supported labels (same as the radio widget):\n",
        "\n",
        "        \"gpt2\"\n",
        "        \"llama-3.1-8b\"          â†’ FP16 checkpoint â†’ 4-bit NF4 + LoRA\n",
        "        \"llama-3.1-8b-int4\"     â†’ same as above (different label)\n",
        "        \"llama-3.2-1b\"          â†’ FP16 checkpoint â†’ 4-bit NF4 + LoRA\n",
        "    \"\"\"\n",
        "\n",
        "    model_id = args.llm_model.lower()\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 1) GPT-2  (full precision, trainable)\n",
        "    # ------------------------------------------------------------------\n",
        "    if model_id == \"gpt2\":\n",
        "        gpt_cfg = GPT2Config.from_pretrained(\n",
        "            args.GPT_PATH,\n",
        "            n_embd=args.gpt_n_embd,\n",
        "            n_layer=args.gpt_n_layer,\n",
        "            n_head=args.gpt_n_head,\n",
        "            resid_pdrop=args.gpt_resid_pdrop,\n",
        "            attn_pdrop=args.gpt_attn_pdrop,\n",
        "            embd_pdrop=args.gpt_embd_pdrop,\n",
        "            activation_function=args.gpt_activation_function,\n",
        "        )\n",
        "        llm = AutoModelForCausalLM.from_pretrained(\n",
        "            args.GPT_PATH,\n",
        "            config=gpt_cfg,\n",
        "            local_files_only=True,\n",
        "        )\n",
        "        n_embd = llm.config.n_embd\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 2) Llama-3.1-8B  (FP16 â†’ 4-bit NF4 + LoRA)  â€“ trainable\n",
        "    # ------------------------------------------------------------------\n",
        "    elif model_id in {\"llama-3.1-8b\", \"llama-3.1-8b-int4\"}:\n",
        "        base = AutoModelForCausalLM.from_pretrained(\n",
        "            args.LLAMA_3_1_PATH,          # path to FP16 checkpoint on Drive\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            use_cache=False,\n",
        "            local_files_only=True,\n",
        "\n",
        "            # ----- legacy Bits-and-Bytes 4-bit flags -------------------\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "        base = prepare_model_for_kbit_training(base)\n",
        "\n",
        "        lora_cfg = LoraConfig(\n",
        "            r=args.lora_r,\n",
        "            lora_alpha=args.lora_alpha,\n",
        "            target_modules=args.lora_target_modules,\n",
        "            lora_dropout=args.lora_dropout,\n",
        "            bias=\"none\",\n",
        "            task_type=\"CAUSAL_LM\",\n",
        "        )\n",
        "        llm = get_peft_model(base, lora_cfg)\n",
        "        n_embd = llm.config.hidden_size\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 3) Llama-3.2-1B  (FP16 â†’ 4-bit NF4 + LoRA)  â€“ trainable\n",
        "    # ------------------------------------------------------------------\n",
        "    elif model_id == \"llama-3.2-1b\":\n",
        "        base = AutoModelForCausalLM.from_pretrained(\n",
        "            args.LLAMA_3_2_PATH,          # path to FP16 checkpoint on Drive\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            use_cache=False,\n",
        "            local_files_only=True,\n",
        "\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "        base = prepare_model_for_kbit_training(base)\n",
        "\n",
        "        lora_cfg = LoraConfig(\n",
        "            r=args.lora_r,\n",
        "            lora_alpha=args.lora_alpha,\n",
        "            target_modules=args.lora_target_modules,\n",
        "            lora_dropout=args.lora_dropout,\n",
        "            bias=\"none\",\n",
        "            task_type=\"CAUSAL_LM\",\n",
        "        )\n",
        "        llm = get_peft_model(base, lora_cfg)\n",
        "        n_embd = llm.config.hidden_size\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported llm_model: {args.llm_model}\")\n",
        "\n",
        "    return llm, n_embd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNxTpxAf8QYB"
      },
      "source": [
        "# TRAINING ROUTINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkfbW6YR1ZBa"
      },
      "outputs": [],
      "source": [
        "PROJECT_PATH = '/content/drive/MyDrive/THESIS'\n",
        "TRAINING_PATH = PROJECT_PATH + '/Trainings'\n",
        "DATA_PATH = PROJECT_PATH + '/deap_preprocess_eeg+peripheral_32_40_40_60_128.mat'\n",
        "GPT_PATH  = PROJECT_PATH + '/GPT-2'\n",
        "LLAMA_3_1_PATH = PROJECT_PATH + '/Llama-3.1-8B-Instruct'\n",
        "LLAMA_3_2_PATH = PROJECT_PATH + '/Llama-3.2-1B'\n",
        "LLAMA_3_1_INT4_PATH = PROJECT_PATH + '/Llama-3.1-8B-INT4'\n",
        "\n",
        "\n",
        "FS       = 128   # EEG sampling frequency (Hz)\n",
        "SEQ_LEN  = 512   # Samples per trial after DEAP preprocessing\n",
        "EEG_CH   = 32    # Number of EEG electrodes used\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "SEED = 123\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--EPOCH\",            type=int,   default=150)\n",
        "parser.add_argument(\"--TRAIN_BATCH_SIZE\", type=int,   default=32)\n",
        "parser.add_argument(\"--TEST_BATCH_SIZE\",  type=int,   default=64)\n",
        "parser.add_argument(\"--LR\",               type=float, default=1e-3)\n",
        "parser.add_argument(\"--regular_coeff\",    type=float, default=1e-4)\n",
        "parser.add_argument(\"--Israndom\",         action=\"store_true\")\n",
        "parser.add_argument(\"--labeltype\",        choices=[\"valence\",\"arousal\",\"both\"], default=\"valence\")\n",
        "parser.add_argument(\"--hidden_dim\",       type=int,   default=32)\n",
        "\n",
        "# GPT-2 hyperparameters\n",
        "parser.add_argument(\"--gpt_n_embd\",       type=int,   default=768)\n",
        "parser.add_argument(\"--gpt_n_layer\",      type=int,   default=12)\n",
        "parser.add_argument(\"--gpt_n_head\",       type=int,   default=12)\n",
        "parser.add_argument(\"--gpt_resid_pdrop\",  type=float, default=0.1)\n",
        "parser.add_argument(\"--gpt_attn_pdrop\",   type=float, default=0.1)\n",
        "parser.add_argument(\"--gpt_embd_pdrop\",   type=float, default=0.1)\n",
        "parser.add_argument(\"--gpt_activation_function\",\n",
        "                    choices=[\"relu\",\"silu\",\"gelu\",\"tanh\",\"gelu_new\"], default=\"gelu\")\n",
        "\n",
        "# LLM & fine-tuning settings\n",
        "parser.add_argument(\"--llm_model\",\n",
        "                    default=\"gpt2\",\n",
        "                    help=\"HuggingFace id or local path of the LLM backbone\")\n",
        "parser.add_argument(\"--finetune_llm\",\n",
        "                    action=argparse.BooleanOptionalAction,\n",
        "                    default=True,\n",
        "                    help=\"Enable/disable fine-tuning of the LLM backbone.\")\n",
        "parser.add_argument(\"--llm_lr_scale\", type=float, default=0.5,\n",
        "                    help=\"Multiplier for LLM learning-rate when fine-tuning.\")\n",
        "\n",
        "# â”€â”€ LoRA hyperparameters (only for Llama) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "parser.add_argument(\"--lora_r\",              type=int,   default=16,\n",
        "                    help=\"LoRA rank\")\n",
        "parser.add_argument(\"--lora_alpha\",          type=int,   default=32,\n",
        "                    help=\"LoRA alpha\")\n",
        "parser.add_argument(\"--lora_dropout\",        type=float, default=0.05,\n",
        "                    help=\"LoRA dropout\")\n",
        "parser.add_argument(\"--lora_target_modules\", nargs=\"+\",\n",
        "                    default=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "                             \"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        "                    help=\"Modules to apply LoRA to\")\n",
        "\n",
        "# SEGMENT SETTINGS (in seconds)\n",
        "parser.add_argument(\"--total_sec\",    type=float, default=60.0,\n",
        "                    help=\"Total length of each trial, in seconds (e.g. 60).\")\n",
        "parser.add_argument(\"--segment_sec\",  type=float, default=1.0,\n",
        "                    help=\"Length of the segments to cut each trial into, in seconds.\")\n",
        "\n",
        "## CHUNK SETTINGS (in samples; will be overridden by segment_sec/stride_sec)\n",
        "parser.add_argument(\"--chunk_len\",    type=int, default=64,\n",
        "                    help=\"Window length for Transformer, in samples.\")\n",
        "parser.add_argument(\"--chunk_stride\", type=int, default=32,\n",
        "                    help=\"Hop between windows for Transformer, in samples.\")\n",
        "\n",
        "# Paths\n",
        "parser.add_argument(\"--DATA_PATH\",\n",
        "                    default=DATA_PATH)\n",
        "parser.add_argument(\"--GPT_PATH\", default=GPT_PATH)\n",
        "parser.add_argument(\"--LLAMA_3_1_PATH\", default=LLAMA_3_1_PATH)\n",
        "parser.add_argument(\"--LLAMA_3_2_PATH\", default=LLAMA_3_2_PATH)\n",
        "parser.add_argument(\"--LLAMA_3_1_INT4_PATH\", default=LLAMA_3_1_INT4_PATH)\n",
        "\n",
        "# EEG parameters\n",
        "parser.add_argument(\"--FS\", type=int, default=FS)\n",
        "parser.add_argument(\"--SEQ_LEN\", type=int, default=SEQ_LEN)\n",
        "parser.add_argument(\"--EEG_CH\", type=int, default=EEG_CH)\n",
        "\n",
        "# Loss weighting\n",
        "parser.add_argument(\"--rec_warmup\", type=int, default=3,\n",
        "                    help=\"Skip reconstruction loss for the first N epochs.\")\n",
        "parser.add_argument(\"--loss_rec_weight\", type=float, default=2.0,\n",
        "                    help=\"Weight of the reconstruction loss (after warm-up).\")\n",
        "parser.add_argument(\"--loss_cls_weight\", type=float, default=1.0,\n",
        "                    help=\"Weight of the classification losses.\")\n",
        "\n",
        "# GPU\n",
        "parser.add_argument(\"--gpu_num\", type=int, default=0)\n",
        "\n",
        "# Early Stopping\n",
        "parser.add_argument(\n",
        "    \"--early_stop_patience\", type=int, default=15,\n",
        "    help=\"Number of consecutive epochs without a new best test accuracy before stopping\"\n",
        ")\n",
        "\n",
        "\n",
        "config = parser.parse_args([]) # Pass an empty list to ignore kernel arguments\n",
        "\n",
        "\n",
        "# === Compute everything from seconds + FS ===\n",
        "config.total_len   = int(round(config.total_sec   * config.FS))       # samples per trial\n",
        "config.segment_len = int(round(config.segment_sec * config.FS))       # samples per segment\n",
        "if config.segment_len <= 0 or config.segment_len > config.total_len:\n",
        "    raise ValueError(\"segment_len must be in (0, total_len].\")\n",
        "\n",
        "if config.chunk_len <= 0 or config.chunk_len > config.segment_len:\n",
        "    raise ValueError(\"chunk_len must be in (0, segment_len].\")\n",
        "if config.chunk_stride <= 0:\n",
        "    raise ValueError(\"chunk_stride must be positive.\")\n",
        "\n",
        "config.num_chunks = (config.segment_len - config.chunk_len) // config.chunk_stride + 1\n",
        "if config.num_chunks <= 2:\n",
        "    raise ValueError(\"num_chunks <= 0. Check segment and stride lengths.\")\n",
        "\n",
        "print(f\"[DEBUG] total_len    = {config.total_len} samples   ({config.total_sec}s per trial)\")\n",
        "print(f\"[DEBUG] segment_len  = {config.segment_len} samples   ({config.segment_sec}s per segment)\")\n",
        "print(f\"[DEBUG] chunk_len    = {config.chunk_len} samples   ({config.chunk_len/config.FS:.2f}s windows)\")\n",
        "print(f\"[DEBUG] chunk_stride = {config.chunk_stride} samples   ({config.chunk_stride/config.FS:.2f}s hop)\")\n",
        "print(f\"[DEBUG] num_chunks   = {config.num_chunks} windows per segment\\n\")\n",
        "\n",
        "\n",
        "device = torch.device(f\"cuda:{config.gpu_num}\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDls7Tqu8VYj"
      },
      "outputs": [],
      "source": [
        "def train_one_subject(args,\n",
        "                      subject: int,\n",
        "                      exp_root: Path,\n",
        "                      global_best: dict):\n",
        "    \"\"\"\n",
        "    Train *one* DEAP subject and update global checkpoints\n",
        "    only when a metric beats `global_best[metric]['acc']`.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    best_this : dict\n",
        "        {metric: (best_acc, best_f1, epoch, ckpt_path_or_None)}\n",
        "    \"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # -------------------------------------------------- I/O\n",
        "    ckpt_dir  = exp_root / \"checkpoints\"\n",
        "    plots_dir = exp_root / \"plots\"\n",
        "    ckpt_dir.mkdir(exist_ok=True)\n",
        "    plots_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # history json (per subject, keeps plotting simple & cheap)\n",
        "    metrics_fp = plots_dir / f\"metrics_sub{subject:02d}.json\"\n",
        "\n",
        "    # -------------------------------------------------- W&B\n",
        "    wandb.init(project=\"LLM-Powered Emotion Recognition from Music-Evoked EEG Signals\",\n",
        "               config=vars(args), reinit=True)\n",
        "    wandb.define_metric(\"epoch\")\n",
        "    wandb.define_metric(\"*\", step_metric=\"epoch\", step_sync=True)\n",
        "\n",
        "    # -------------------------------------------------- MODELS\n",
        "    llm_model, n_embd = instantiate_llm(args)\n",
        "    llm_model.to(device)\n",
        "\n",
        "    num_chunks   = args.num_chunks\n",
        "    chunk_len    = args.chunk_len\n",
        "    chunk_stride = args.chunk_stride\n",
        "\n",
        "    learn_tok = torch.randn((1, n_embd), requires_grad=True, device=device)\n",
        "\n",
        "    eeg_trans = EEGTransformer(d_eeg=args.EEG_CH,\n",
        "                               seq_length=chunk_len,\n",
        "                               feature_dim=args.hidden_dim,\n",
        "                               output_dim=n_embd).to(device)\n",
        "    final_t1  = FinalClassifier(n_embd, num_chunks,\n",
        "                                4 if args.labeltype == \"both\" else 2).to(device)\n",
        "    teacher2  = DGCNN(num_electrodes=args.EEG_CH,\n",
        "                      in_channels=args.segment_len,\n",
        "                      num_embed=n_embd).to(device)\n",
        "    final_t2  = FinalClassifier(n_embd, 1,\n",
        "                                4 if args.labeltype == \"both\" else 2).to(device)\n",
        "\n",
        "    # -------------------------------------------------- OPTIMIZER\n",
        "    base_params = [*eeg_trans.parameters(),\n",
        "                   *final_t1.parameters(),\n",
        "                   *teacher2.parameters(),\n",
        "                   *final_t2.parameters(),\n",
        "                   learn_tok]\n",
        "    optim_groups = [{\"params\": base_params, \"lr\": args.LR}]\n",
        "    if args.finetune_llm:\n",
        "        optim_groups.append({\"params\": llm_model.parameters(),\n",
        "                             \"lr\": args.LR * args.llm_lr_scale})\n",
        "\n",
        "    optimizer  = torch.optim.AdamW(optim_groups, weight_decay=args.regular_coeff)\n",
        "\n",
        "    # -------------------------------------------------- DATA\n",
        "    mat    = scipy.io.loadmat(args.DATA_PATH)\n",
        "    Xsub   = mat[\"X\"][subject]\n",
        "    Ysub   = mat[\"Y\"][subject]\n",
        "\n",
        "    # restrict to first args.EEG_CH channels\n",
        "    Xsub = Xsub[:, :args.EEG_CH, :, :]\n",
        "\n",
        "    # reshape, segment and repeat labels exactly like your original code\n",
        "    Xtime = Xsub.reshape(40, args.EEG_CH, args.total_len)\n",
        "    segs  = torch.from_numpy(Xtime).float() \\\n",
        "                .unfold(2, args.segment_len, args.segment_len)\n",
        "    n_segs = segs.size(2)\n",
        "    eeg = segs.permute(0, 2, 1, 3).reshape(-1, args.EEG_CH, args.segment_len).numpy()\n",
        "\n",
        "    Yseg = torch.from_numpy(Ysub).float().repeat_interleave(n_segs, dim=0)\n",
        "    bin_ = lambda v: (v >= 5).long()\n",
        "\n",
        "    if args.labeltype == \"valence\":\n",
        "        Y_bin = bin_(Yseg[:, 0]).numpy()\n",
        "    elif args.labeltype == \"arousal\":\n",
        "        Y_bin = bin_(Yseg[:, 1]).numpy()\n",
        "    else:\n",
        "        Y_bin = (2 * bin_(Yseg[:, 0]) + bin_(Yseg[:, 1])).numpy()\n",
        "\n",
        "    idx_train, idx_test = train_test_split(np.arange(len(Y_bin)),\n",
        "                                           test_size=0.2,\n",
        "                                           random_state=SEED,\n",
        "                                           stratify=Y_bin)\n",
        "\n",
        "    class_counts  = np.bincount(Y_bin[idx_train])\n",
        "    class_weights = 1.0 / class_counts\n",
        "    ce_weights    = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
        "\n",
        "    sampler = WeightedRandomSampler(torch.tensor(class_weights[Y_bin[idx_train]],\n",
        "                                                 dtype=torch.double),\n",
        "                                    num_samples=len(idx_train) * 2,\n",
        "                                    replacement=True)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(torch.tensor(eeg[idx_train]),\n",
        "                      torch.tensor(Y_bin[idx_train])),\n",
        "        batch_size=args.TRAIN_BATCH_SIZE,\n",
        "        sampler=sampler,\n",
        "        shuffle=False,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        TensorDataset(torch.tensor(eeg[idx_test]),\n",
        "                      torch.tensor(Y_bin[idx_test])),\n",
        "        batch_size=args.TEST_BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------- SCHEDULER\n",
        "    tot_steps = args.EPOCH * len(train_loader)\n",
        "    warmup    = int(0.05 * tot_steps)\n",
        "    scheduler = LambdaLR(\n",
        "        optimizer,\n",
        "        lambda s: s / warmup if s < warmup\n",
        "        else 0.5 * (1 + np.cos(np.pi * (s - warmup) / (tot_steps - warmup)))\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------- HISTORY & BESTS\n",
        "    if metrics_fp.exists():\n",
        "        history = json.load(open(metrics_fp))\n",
        "    else:\n",
        "        history = {\"train_loss\": []}\n",
        "        for m in [\"temp\", \"spat\", \"avg\", \"conf\"]:\n",
        "            for k in [\"train_acc_\", \"test_acc_\", \"train_f1_\", \"test_f1_\"]:\n",
        "                history[k + m] = []\n",
        "\n",
        "    best_this = {h: (0.0, 0.0, None, None) for h in [\"temp\", \"spat\", \"avg\", \"conf\"]}\n",
        "\n",
        "    # -------------------------------------------------- EPOCH LOOP\n",
        "    pbar = tqdm(total=args.EPOCH, desc=\"Epochs\", unit=\"ep\")\n",
        "    wait_epochs = 0\n",
        "    best_acc    = 0.0\n",
        "\n",
        "    for epoch in range(args.EPOCH):\n",
        "        t0 = time.time()\n",
        "\n",
        "        # -------------------- TRAIN --------------------\n",
        "        eeg_trans.train(); teacher2.train()\n",
        "        final_t1.train();  final_t2.train()\n",
        "        if args.finetune_llm: llm_model.train()\n",
        "\n",
        "        epoch_loss = steps = 0\n",
        "        corr_temp = corr_spat = corr_avg = corr_conf = 0\n",
        "        preds_t = []\n",
        "        preds_s = []\n",
        "        preds_a = []\n",
        "        preds_c = []\n",
        "        targets = []\n",
        "\n",
        "        for bx, by in train_loader:\n",
        "            by = by.to(device)\n",
        "            beeg = bx.to(device)\n",
        "            B = beeg.size(0)\n",
        "\n",
        "            with autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
        "                chunks = (beeg\n",
        "                          .permute(0, 2, 1)                          # (B, seg_len, 32)\n",
        "                          .unfold(1, chunk_len, chunk_stride)        # (B, n_chunks, chunk_len, 32)\n",
        "                          .permute(0, 1, 3, 2)\n",
        "                          .contiguous()\n",
        "                          .view(-1, chunk_len, 32))                  # (B*n_chunks, chunk_len, 32)\n",
        "\n",
        "                fused = eeg_trans(chunks).view(B, num_chunks, n_embd)\n",
        "\n",
        "                # reconstruction loss\n",
        "                lr_rec = 0.0\n",
        "                if num_chunks > 1:\n",
        "                    for i in range(2, num_chunks + 1):\n",
        "                        m = fused.clone()\n",
        "                        m[:, i:] = 0\n",
        "                        m[:, i - 1] = learn_tok\n",
        "                        outs = llm_model(inputs_embeds=m,\n",
        "                                         output_hidden_states=True)\n",
        "                        ph = outs.hidden_states[-1][:, i - 1, :]\n",
        "                        th = fused[:, i - 1, :].detach()\n",
        "                        lr_rec += F.mse_loss(ph, th)\n",
        "                    lr_rec = lr_rec / (num_chunks - 1)\n",
        "\n",
        "                sf     = teacher2(beeg)\n",
        "                _, lt  = final_t1(fused)\n",
        "                _, ls  = final_t2(sf)\n",
        "\n",
        "                cls_t = F.cross_entropy(lt, by, weight=ce_weights)\n",
        "                cls_s = F.cross_entropy(ls, by, weight=ce_weights)\n",
        "                rec_w = 0.0 if epoch < args.rec_warmup else args.loss_rec_weight * lr_rec\n",
        "\n",
        "                loss  = args.loss_cls_weight * (2.0 * cls_t + 1.0 * cls_s) + rec_w\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item(); steps += 1\n",
        "\n",
        "            pt = lt.argmax(1); ps = ls.argmax(1)\n",
        "            pa = ((lt + ls) / 2).argmax(1)\n",
        "            ct = F.softmax(lt, dim=1).max(1)\n",
        "            cs = F.softmax(ls, dim=1).max(1)\n",
        "            pc = torch.where(ct.values > cs.values, pt, ps)\n",
        "\n",
        "            corr_temp += (pt == by).sum().item()\n",
        "            corr_spat += (ps == by).sum().item()\n",
        "            corr_avg  += (pa == by).sum().item()\n",
        "            corr_conf += (pc == by).sum().item()\n",
        "\n",
        "            preds_t.extend(pt.cpu().tolist())\n",
        "            preds_s.extend(ps.cpu().tolist())\n",
        "            preds_a.extend(pa.cpu().tolist())\n",
        "            preds_c.extend(pc.cpu().tolist())\n",
        "            targets.extend(by.cpu().tolist())\n",
        "\n",
        "        # ------------- TRAIN METRICS -------------\n",
        "        n_tr = len(targets)\n",
        "        acc_t_tr = corr_temp / n_tr; acc_s_tr = corr_spat / n_tr\n",
        "        acc_a_tr = corr_avg  / n_tr; acc_c_tr = corr_conf / n_tr\n",
        "        f1_t_tr  = f1_score(targets, preds_t, average=\"weighted\")\n",
        "        f1_s_tr  = f1_score(targets, preds_s, average=\"weighted\")\n",
        "        f1_a_tr  = f1_score(targets, preds_a, average=\"weighted\")\n",
        "        f1_c_tr  = f1_score(targets, preds_c, average=\"weighted\")\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch+1}/{args.EPOCH}]\\n\"\n",
        "            f\"Train loss: {epoch_loss/steps:.4f}\\n\"\n",
        "            f\"Temp-acc: {acc_t_tr:.3f} | Spat-acc: {acc_s_tr:.3f} | \"\n",
        "            f\"Avg-acc: {acc_a_tr:.3f} | Conf-acc: {acc_c_tr:.3f}\\n\"\n",
        "            f\"F1-temp: {f1_t_tr:.3f} | F1-spat: {f1_s_tr:.3f} | \"\n",
        "            f\"F1-avg: {f1_a_tr:.3f} | F1-conf: {f1_c_tr:.3f}\\n\"\n",
        "        )\n",
        "\n",
        "        # -------------------- EVAL --------------------\n",
        "        eeg_trans.eval(); teacher2.eval()\n",
        "        final_t1.eval();  final_t2.eval(); llm_model.eval()\n",
        "\n",
        "        corr_temp = corr_spat = corr_avg = corr_conf = 0\n",
        "        preds_t = []\n",
        "        preds_s = []\n",
        "        preds_a = []\n",
        "        preds_c = []\n",
        "        targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for bx, by in test_loader:\n",
        "                by   = by.to(device)\n",
        "                beeg = bx.to(device)\n",
        "                B    = beeg.size(0)\n",
        "\n",
        "                chunks = (beeg.permute(0, 2, 1)\n",
        "                               .unfold(1, chunk_len, chunk_stride)\n",
        "                               .permute(0, 1, 3, 2)\n",
        "                               .contiguous()\n",
        "                               .view(-1, chunk_len, 32))\n",
        "\n",
        "                with autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
        "                    fused = eeg_trans(chunks).view(B, num_chunks, n_embd)\n",
        "                    sf    = teacher2(beeg)\n",
        "                    _, lt = final_t1(fused)\n",
        "                    _, ls = final_t2(sf)\n",
        "\n",
        "                    pt = lt.argmax(1); ps = ls.argmax(1)\n",
        "                    pa = ((lt + ls) / 2).argmax(1)\n",
        "                    ct = F.softmax(lt, dim=1).max(1)\n",
        "                    cs = F.softmax(ls, dim=1).max(1)\n",
        "                    pc = torch.where(ct.values > cs.values, pt, ps)\n",
        "\n",
        "                corr_temp += (pt == by).sum().item()\n",
        "                corr_spat += (ps == by).sum().item()\n",
        "                corr_avg  += (pa == by).sum().item()\n",
        "                corr_conf += (pc == by).sum().item()\n",
        "\n",
        "                preds_t.extend(pt.cpu().tolist())\n",
        "                preds_s.extend(ps.cpu().tolist())\n",
        "                preds_a.extend(pa.cpu().tolist())\n",
        "                preds_c.extend(pc.cpu().tolist())\n",
        "                targets.extend(by.cpu().tolist())\n",
        "\n",
        "        # ------------- TEST METRICS -------------\n",
        "        n_te = len(targets)\n",
        "        acc_temp = corr_temp / n_te; acc_spat = corr_spat / n_te\n",
        "        acc_avg  = corr_avg  / n_te; acc_conf = corr_conf / n_te\n",
        "        f1_temp  = f1_score(targets, preds_t, average=\"weighted\")\n",
        "        f1_spat  = f1_score(targets, preds_s, average=\"weighted\")\n",
        "        f1_avg   = f1_score(targets, preds_a, average=\"weighted\")\n",
        "        f1_conf  = f1_score(targets, preds_c, average=\"weighted\")\n",
        "\n",
        "        print(\n",
        "            f\"â†’ Test\\n\"\n",
        "            f\"Temp-acc: {acc_temp:.3f} | Spat-acc: {acc_spat:.3f} | \"\n",
        "            f\"Avg-acc: {acc_avg:.3f} | Conf-acc: {acc_conf:.3f}\\n\"\n",
        "            f\"F1-temp: {f1_temp:.3f} | F1-spat: {f1_spat:.3f} | \"\n",
        "            f\"F1-avg: {f1_avg:.3f} | F1-conf: {f1_conf:.3f}\\n\"\n",
        "        )\n",
        "\n",
        "        test_accs = {\"temp\": acc_temp, \"spat\": acc_spat,\n",
        "                     \"avg\":  acc_avg,  \"conf\": acc_conf}\n",
        "        f1_curr   = {\"temp\": f1_temp,  \"spat\": f1_spat,\n",
        "                     \"avg\":  f1_avg,   \"conf\": f1_conf}\n",
        "\n",
        "        # ------------- EARLY STOPPING -------------\n",
        "        best_type, curr = max(test_accs.items(), key=lambda x: x[1])\n",
        "\n",
        "        if curr > best_acc:\n",
        "            best_acc = curr\n",
        "            wait_epochs = 0\n",
        "            print(f\"âœ… New best test acc: {best_acc:.3f} ({best_type})\")\n",
        "\n",
        "        elif args.early_stop_patience > 0:\n",
        "            wait_epochs += 1\n",
        "            print(f\"â³  No improvement for {wait_epochs}/{args.early_stop_patience} epoch(s)\")\n",
        "\n",
        "            if wait_epochs >= args.early_stop_patience:\n",
        "                print(f\"ðŸ›‘  Early stopping: no new best accuracy for {args.early_stop_patience} epochs\")\n",
        "                break\n",
        "\n",
        "\n",
        "        # ------------- GLOBAL BEST CHECKPOINT -------------\n",
        "        for h, acc_curr in test_accs.items():\n",
        "            if acc_curr > global_best[h][\"acc\"]:\n",
        "                # delete previous checkpoint if any\n",
        "                old_ckpt = global_best[h][\"ckpt\"]\n",
        "                if old_ckpt and Path(old_ckpt).exists():\n",
        "                    Path(old_ckpt).unlink()\n",
        "\n",
        "                ckpt_name = f\"best_{h}_acc_sub{subject:02d}_ep{epoch:03d}.pth\"\n",
        "                ckpt_path = ckpt_dir / ckpt_name\n",
        "\n",
        "                # Save new best checkpoint\n",
        "                torch.save({\n",
        "                    \"epoch\": epoch,\n",
        "                    \"eeg_transformer\": eeg_trans.state_dict(),\n",
        "                    \"teacher2\":        teacher2.state_dict(),\n",
        "                    \"final_t1\":        final_t1.state_dict(),\n",
        "                    \"final_t2\":        final_t2.state_dict(),\n",
        "                    \"llm_model\":       llm_model.state_dict(),\n",
        "                    \"learn_tok\":       learn_tok.data,\n",
        "                    \"optim\":           optimizer.state_dict(),\n",
        "                    \"acc\":             acc_curr,\n",
        "                    \"f1\":              f1_curr[h],\n",
        "                    \"subject\":         subject,\n",
        "                }, ckpt_path)\n",
        "\n",
        "                # Update global reference\n",
        "                global_best[h] = {\n",
        "                    \"acc\": acc_curr,\n",
        "                    \"f1\":  f1_curr[h],\n",
        "                    \"subject\": subject,\n",
        "                    \"epoch\": epoch,\n",
        "                    \"ckpt\": str(ckpt_path)\n",
        "                }\n",
        "\n",
        "                # Update subject-local best too\n",
        "                best_this[h] = (acc_curr, f1_curr[h], epoch, str(ckpt_path))\n",
        "\n",
        "\n",
        "        # ------------- HISTORY UPDATE -------------\n",
        "        history[\"train_loss\"].append(epoch_loss / steps)\n",
        "        for name, val in [(\"temp\", acc_t_tr), (\"spat\", acc_s_tr),\n",
        "                          (\"avg\", acc_a_tr), (\"conf\", acc_c_tr)]:\n",
        "            history[f\"train_acc_{name}\"].append(val)\n",
        "        for name, val in [(\"temp\", f1_t_tr), (\"spat\", f1_s_tr),\n",
        "                          (\"avg\", f1_a_tr), (\"conf\", f1_c_tr)]:\n",
        "            history[f\"train_f1_{name}\"].append(val)\n",
        "        for name, val in [(\"temp\", acc_temp), (\"spat\", acc_spat),\n",
        "                          (\"avg\", acc_avg),  (\"conf\", acc_conf)]:\n",
        "            history[f\"test_acc_{name}\"].append(val)\n",
        "        for name, val in [(\"temp\", f1_temp), (\"spat\", f1_spat),\n",
        "                          (\"avg\", f1_avg),  (\"conf\", f1_conf)]:\n",
        "            history[f\"test_f1_{name}\"].append(val)\n",
        "\n",
        "        with metrics_fp.open(\"w\") as f:\n",
        "            json.dump(history, f, indent=4)\n",
        "\n",
        "        # ------------- LOGGING -------------\n",
        "        wandb.log({\"epoch\": epoch + 1,\n",
        "                   \"train_loss\": epoch_loss / steps,\n",
        "                   \"train_acc_temp\": acc_t_tr,\n",
        "                   \"train_acc_spat\": acc_s_tr,\n",
        "                   \"train_acc_avg\":  acc_a_tr,\n",
        "                   \"train_acc_conf\": acc_c_tr,\n",
        "                   \"test_acc_temp\":  acc_temp,\n",
        "                   \"test_acc_spat\":  acc_spat,\n",
        "                   \"test_acc_avg\":   acc_avg,\n",
        "                   \"test_acc_conf\":  acc_conf}, step=epoch + 1)\n",
        "\n",
        "        epoch_time = time.time() - t0\n",
        "        pbar.update(1)\n",
        "        pbar.set_postfix(epoch_time=f\"{epoch_time:.1f}s\")\n",
        "\n",
        "    pbar.close()\n",
        "    wandb.finish()\n",
        "    print(f\"\\nâ–¶ Finished subject {subject}. Best acc: {best_acc:.4f}!\")\n",
        "    return best_this\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxQLFwGGcQqr"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Interactive model picker  â€“ run this *before* your training loop\n",
        "# ---------------------------------------------------------------\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Map GUI labels â†’ HF model IDs you use elsewhere\n",
        "MODEL_MAP = {\n",
        "    \"GPT-2\":                     \"gpt2\",\n",
        "    \"Llama-3.1-8B  (FP16)\":      \"Llama-3.1-8B\",\n",
        "    \"Llama-3.1-8B  (INT4-AWQ)\":  \"Llama-3.1-8B-INT4\",\n",
        "    \"Llama-3.2-1B  (FP16)\":      \"Llama-3.2-1B\",\n",
        "}\n",
        "\n",
        "# RadioButtons give one-click selection without typing\n",
        "picker = widgets.RadioButtons(\n",
        "    options=list(MODEL_MAP.keys()),\n",
        "    description=\"LLM:\",\n",
        "    layout={\"width\": \"max-content\"},\n",
        ")\n",
        "\n",
        "info_box = widgets.Output()\n",
        "\n",
        "def on_change(change):\n",
        "    \"\"\"When the user picks a new radio item, update config.llm_model\"\"\"\n",
        "    if change[\"name\"] == \"value\":\n",
        "        config.llm_model = MODEL_MAP[change[\"new\"]]\n",
        "        with info_box:\n",
        "            clear_output()\n",
        "            print(f\"â–º  `config.llm_model` set to: {config.llm_model}\")\n",
        "\n",
        "# Register the callback and show the widget\n",
        "picker.observe(on_change, names=\"value\")\n",
        "display(picker, info_box)\n",
        "\n",
        "# (Optional) pre-select the first entry so config is never undefined\n",
        "picker.value = list(MODEL_MAP.keys())[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_RJLU2QOxT9"
      },
      "outputs": [],
      "source": [
        "# Create experiment folder\n",
        "tz   = pytz.timezone(\"Europe/Rome\")\n",
        "now  = datetime.now(tz).strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "EXP_ROOT = Path(TRAINING_PATH) / f\"{now}_{config.llm_model}_{config.labeltype}\"\n",
        "EXP_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save configuration once\n",
        "with (EXP_ROOT / \"config.json\").open(\"w\") as fp:\n",
        "    json.dump(vars(config), fp, indent=4)\n",
        "\n",
        "STATE_FP = EXP_ROOT / \"experiment_state.json\"\n",
        "\n",
        "if STATE_FP.exists():                        # â”€â”€â”€â”€â”€ RESUME EXPERIMENT â”€â”€â”€â”€â”€\n",
        "    print(\"â–¶  Resuming experiment from saved state...\")\n",
        "    with STATE_FP.open() as fp:\n",
        "        state = json.load(fp)\n",
        "    start_subj  = state[\"next_subject\"]\n",
        "    best_global = state[\"best_overall\"]\n",
        "    all_best    = state[\"per_subject_best\"]\n",
        "else:                                        # â”€â”€â”€â”€â”€ NEW EXPERIMENT â”€â”€â”€â”€â”€â”€\n",
        "    start_subj  = 0\n",
        "    best_global = {h: {\"acc\": 0.0, \"f1\": 0.0,\n",
        "                       \"subject\": None, \"epoch\": None, \"ckpt\": None}\n",
        "                   for h in [\"temp\", \"spat\", \"avg\", \"conf\"]}\n",
        "    all_best    = {h: {\"acc\": [], \"f1\": []}\n",
        "                   for h in [\"temp\", \"spat\", \"avg\", \"conf\"]}\n",
        "\n",
        "NUM_SUBJECTS = 32\n",
        "\n",
        "# ---------------------------------------------------------------- MAIN LOOP\n",
        "for subj in range(start_subj, NUM_SUBJECTS):\n",
        "    print(f\"\\n===== SUBJECT {subj:02d} / {NUM_SUBJECTS-1} =====\")\n",
        "\n",
        "    best_subj = train_one_subject(args=config,\n",
        "                                  subject=subj,\n",
        "                                  exp_root=EXP_ROOT,\n",
        "                                  global_best=best_global)\n",
        "\n",
        "    # --------- 1) APPEND PER-SUBJECT RESULTS ---------------------------\n",
        "    for h in [\"temp\", \"spat\", \"avg\", \"conf\"]:\n",
        "        acc, f1, ep, ckpt_path = best_subj[h]\n",
        "        all_best[h][\"acc\"].append(acc)\n",
        "        all_best[h][\"f1\"].append(f1)\n",
        "\n",
        "    # --------- 2) UPDATE GLOBAL BESTS ----------------------------------\n",
        "    for h in [\"temp\", \"spat\", \"avg\", \"conf\"]:\n",
        "        acc, f1, ep, ckpt_path = best_subj[h]\n",
        "        if acc > best_global[h][\"acc\"]:\n",
        "            # delete previous best checkpoint for this metric (if any)\n",
        "            old = best_global[h][\"ckpt\"]\n",
        "            if old and Path(old).exists():\n",
        "                Path(old).unlink()\n",
        "            best_global[h] = {\"acc\": acc,\n",
        "                              \"f1\":  f1,\n",
        "                              \"subject\": subj,\n",
        "                              \"epoch\":   ep,\n",
        "                              \"ckpt\":    ckpt_path}\n",
        "\n",
        "    # --------- 3) SAVE STATE AFTER EACH SUBJECT ------------------------\n",
        "    with STATE_FP.open(\"w\") as fp:\n",
        "        json.dump({\"next_subject\":     subj + 1,\n",
        "                   \"best_overall\":     best_global,\n",
        "                   \"per_subject_best\": all_best},\n",
        "                  fp, indent=2)\n",
        "\n",
        "# ---------------------------------------------------------------- SUMMARY\n",
        "mean_best = {\n",
        "    h: {\n",
        "        \"acc\": float(np.mean(all_best[h][\"acc\"])) if all_best[h][\"acc\"] else 0.0,\n",
        "        \"f1\":  float(np.mean(all_best[h][\"f1\"]))  if all_best[h][\"f1\"]  else 0.0\n",
        "    }\n",
        "    for h in all_best\n",
        "}\n",
        "\n",
        "print(\"\\nâœ”  TRAINING COMPLETE. Global best metrics:\")\n",
        "for h, d in best_global.items():\n",
        "    print(f\"{h:4}  ACC {d['acc']:.3f}  F1 {d['f1']:.3f}  \"\n",
        "          f\"(sub={d['subject']}, ep={d['epoch']})\")\n",
        "\n",
        "print(\"\\nâ”€â”€â”€ MEAN OF PER-SUBJECT BESTS â”€â”€â”€\")\n",
        "for h, m in mean_best.items():\n",
        "    print(f\"{h:4}  ACC {m['acc']:.3f}  F1 {m['f1']:.3f}\")\n",
        "\n",
        "# ---------------------------------------------------------------- SAVE SUMMARY\n",
        "with (EXP_ROOT / \"best_test_metrics.json\").open(\"w\") as fp:\n",
        "    json.dump({\n",
        "        \"per_subject_best\": all_best,\n",
        "        \"mean_best\":        mean_best\n",
        "    }, fp, indent=2)\n",
        "\n",
        "print(f\"\\nâœ”  Summary saved to {(EXP_ROOT / 'best_test_metrics.json').as_posix()}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6XMFcwd-0XPu"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}